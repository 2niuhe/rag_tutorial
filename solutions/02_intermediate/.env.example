# 本地模型配置
LOCAL_EMBEDDING_MODEL=paraphrase-multilingual-MiniLM-L12-v2

# 本地LLM配置（如果需要）
# LOCAL_LLM_MODEL=llama-2-7b-chat

# 向量数据库配置
VECTOR_DB_TYPE=chroma  # 'chroma' 或 'faiss'
CHROMA_PERSIST_DIRECTORY=./chroma_db
COLLECTION_NAME=intermediate_rag_collection

# 文档处理配置
CHUNK_SIZE=1000
CHUNK_OVERLAP=200

# 检索配置
RETRIEVER_TYPE=vector  # 'vector' 或 'hybrid'
TOP_K=5
SEARCH_TYPE=similarity  # 'similarity' 或 'mmr'

# 语言模型配置
TEMPERATURE=0
MAX_TOKENS=2000
STREAMING=True

# 语料库路径
CORPUS_PATH=../../corpus
